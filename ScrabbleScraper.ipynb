{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: ScrabbleScraper.ipynb\n",
    "# Version: Python 3.9.7\n",
    "# Author: Anthony Gallante\n",
    "# Date: January 4, 2024\n",
    "# Description: Python script to download annotated Scrabble games from www.cross-tables.com\n",
    "#              and save them in the 'Scrabble Games' directory.\n",
    "\n",
    "# Importing necessary libraries\n",
    "import requests, os, bs4\n",
    "\n",
    "# Variable Declaration\n",
    "game_id = 45400                                  # Initial game ID to start downloading from\n",
    "download_button_text = 'Download .gcg game file' # Text to identify the download button on the website\n",
    "site_url = 'https://www.cross-tables.com/'       # Base URL for the website\n",
    "\n",
    "# Creating a directory for storing downloaded files (if it doesn't exist)\n",
    "directory = 'Scrabble Games'\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Headers to simulate a user agent (preventing potential blocking from the website)\n",
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)' + \\\n",
    "             'AppleWebKit/537.36 (KHTML, like Gecko)' + \\\n",
    "             'Chrome/102.0.0.0' + \\\n",
    "             'Safari/537.36'\n",
    "headers = {'user-agent': user_agent}\n",
    "\n",
    "# Loop through games with decreasing IDs until game_id is not greater than 0\n",
    "while game_id > 0:\n",
    "\n",
    "    # Constructing the URL for the annotated game using the current game_id\n",
    "    url = site_url + 'annotated.php?u=' + str(game_id) + '#100#'\n",
    "    print(f'Navigating to Game {game_id} ...')\n",
    "\n",
    "    # Sending a request to the website and getting the response\n",
    "    res = requests.get(url, headers=headers)\n",
    "    res.raise_for_status() # Raise an exception for bad responses\n",
    "\n",
    "    # Creating a BeautifulSoup object to parse the HTML\n",
    "    soup = bs4.BeautifulSoup(res.text)\n",
    "\n",
    "    # Extracting the text from the first paragraph on the website\n",
    "    website_text = soup.select('p')[0].text\n",
    "\n",
    "    # Checking if the game is available on the website\n",
    "    if 'There is no annotated game with that id.' in website_text:\n",
    "        print(f'Game {game_id} unavailable.')\n",
    "\n",
    "    else:\n",
    "            # Extracting the download URL for the .gcg file\n",
    "            download_url = site_url + soup.find('a', text=download_button_text).get('href')\n",
    "            \n",
    "            # Sending a request to the download URL and getting the response\n",
    "            res = requests.get(download_url, headers=headers)\n",
    "            res.raise_for_status() # Raise an exception for bad responses\n",
    "\n",
    "            # Opening each .gcg file and writing to the \"Scrabble Games\" directory in binary mode\n",
    "            print(f'Downloading .gcg file for game {game_id}.')\n",
    "            gcg_file = open(os.path.join(directory, os.path.basename(download_url)), 'wb')\n",
    "            \n",
    "            # Writing the file in chunks\n",
    "            for chunk in res.iter_content(100_000):\n",
    "                gcg_file.write(chunk)\n",
    "            gcg_file.close()\n",
    "    \n",
    "    # Decreasing the game_id for the next iteration\n",
    "    game_id -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
